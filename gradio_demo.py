import gradio as gr
import pandas as pd
import time
import re
import os
import json
import ast
from datetime import datetime, timedelta
from modules.agent import OpenAICommentAnalysisAgent, API2DCommentAnalysisAgent, QwenCommentAnalysisAgent
from modules.utils import csv_enter, amz_xlsx_enter
from modules.classes import POINTS

from modules.data_analyzor import DataAnalyzor
from modules.point_extractor import extract_output, remove_duplicate_values
from modules.visualizor import create_quick_visualization

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs("./buffer", exist_ok=True)

# ç”¨äºå­˜å‚¨æ´»è·ƒç”¨æˆ·ä¿¡æ¯
active_users = {}

def get_active_users():
    """è·å–å½“å‰æ´»è·ƒç”¨æˆ·ä¿¡æ¯"""
    current_time = time.time()
    # æ¸…ç†è¶…è¿‡30åˆ†é’Ÿæœªæ´»åŠ¨çš„ç”¨æˆ·
    for user_id, info in list(active_users.items()):
        if current_time - info['last_active'] > 1800:  # 30åˆ†é’Ÿ
            del active_users[user_id]
    
    # æ ¼å¼åŒ–æ´»è·ƒç”¨æˆ·ä¿¡æ¯
    if not active_users:
        return "å½“å‰æ²¡æœ‰æ´»è·ƒç”¨æˆ·"
    
    user_info = "å½“å‰æ´»è·ƒç”¨æˆ·ï¼š\n"
    for user_id, info in active_users.items():
        user_info += f"- ç”¨æˆ· {user_id}: æ­£åœ¨å¤„ç† {info['file_name']}ï¼Œå·²å¤„ç† {info['progress']} æ¡è¯„è®º\n"
    return user_info

def update_user_status(user_id, file_name, progress, total):
    """æ›´æ–°ç”¨æˆ·çŠ¶æ€"""
    active_users[user_id] = {
        'file_name': file_name,
        'progress': f"{progress}/{total}",
        'last_active': time.time()
    }

def analyze_reviews(file, asin, model_type, api_key, product_type, template, 
                   need_translate, need_inspect, need_points_extract, progress=gr.Progress()):
    if file is None and asin == "":
        return "è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥ ASIN", None

    # ç”Ÿæˆç”¨æˆ·ID
    user_id = str(int(time.time()))
    
    progress_text = ""
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if file is not None:
        base_name = os.path.splitext(os.path.basename(file.name))[0]
        output_csv = f"./buffer/{base_name}_analyzed.csv"
        output_xlsx = f"./buffer/{base_name}_analyzed.xlsx"
        file_name = base_name
    else:
        output_csv = f"./buffer/{asin}_analyzed.csv"
        output_xlsx = f"./buffer/{asin}_analyzed.xlsx"
        file_name = asin

    try:
        if file is not None:
            if file.name.endswith('.csv'):
                df = csv_enter(file.name)
            elif file.name.endswith('.xlsx'):
                df = amz_xlsx_enter(file.name)
            else:
                return "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶", None
        else:
            # TODO: å®ç°é€šè¿‡ ASIN æŠ“å–æ•°æ®çš„åŠŸèƒ½
            return "ASIN æŠ“å–åŠŸèƒ½å°šæœªå®ç°", None

        # åˆå§‹åŒ–è¯„è®ºåˆ†æä»£ç†
        if model_type == "OpenAI":
            agent = OpenAICommentAnalysisAgent(api_key, product_type, template)
        elif model_type == "API2D":
            agent = API2DCommentAnalysisAgent(api_key, product_type, template)
        elif model_type == "Qwen":
            agent = QwenCommentAnalysisAgent(api_key, product_type, template)
        else:
            return "ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹", None

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤„ç†ç»“æœ
        if not os.path.exists(output_csv):
            # åˆ›å»ºæ–°æ–‡ä»¶
            columns = list(df.columns) + ['ç¿»è¯‘è¯„è®º', 'åˆ†æç»“æœ', 'è§‚ç‚¹æå–', 'æ£€æŸ¥ç»“æœ', 'å¥½å·®è¯„ç»“æœ']
            pd.DataFrame(columns=columns).to_csv(output_csv, index=False, encoding='utf-8-sig')
            start_index = 0
        else:
            # è¯»å–å·²å¤„ç†çš„ç»“æœ
            df_processed = pd.read_csv(output_csv)
            start_index = len(df_processed)
            progress_text += f"å‘ç°å·²æœ‰å¤„ç†ç»“æœï¼Œä»ç¬¬ {start_index + 1} æ¡å¼€å§‹ç»§ç»­å¤„ç†\n"

        # åˆ†æè¯„è®º
        total_comments = len(df)
        if start_index >= total_comments:
            return "æ‰€æœ‰è¯„è®ºå·²å¤„ç†å®Œæˆ", output_xlsx

        progress(0, desc=f"å¼€å§‹åˆ†æè¯„è®º... (ä»ç¬¬ {start_index + 1} æ¡å¼€å§‹)")
        
        for idx, row in df.iloc[start_index:].iterrows():
            try:
                comment = row['è¯„è®ºå†…å®¹']
                progress_text += f"åˆ†æä¸­ï¼š{idx+1}/{total_comments} æ¡\n"
                progress((idx - start_index + 1) / (total_comments - start_index), 
                        desc=f"æ­£åœ¨åˆ†æç¬¬ {idx+1}/{total_comments} æ¡è¯„è®º")
                
                # æ›´æ–°ç”¨æˆ·çŠ¶æ€
                update_user_status(user_id, file_name, idx + 1, total_comments)
                
                # åˆ†æè¯„è®ºï¼ˆå¿…é¡»æ‰§è¡Œï¼‰
                analysis_result = agent.comment_analyze(comment)
                
                # å¯é€‰åŠŸèƒ½
                translated_comment = agent.translate(comment) if need_translate else ""
                points_result = agent.points_extract(comment) if need_points_extract else ""
                inspection_result = agent.inspect(comment, analysis_result) if need_inspect else ""
                
                # æå–å¥½å·®è¯„ç»“æœ
                output_result = extract_output(analysis_result)
                output_result = remove_duplicate_values(output_result)
                
                # åˆ›å»ºå•æ¡ç»“æœï¼Œä¿ç•™åŸå§‹æ•°æ®
                result = row.to_dict()
                # æ·»åŠ åˆ†æç»“æœ
                result.update({
                    'ç¿»è¯‘è¯„è®º': translated_comment,
                    'åˆ†æç»“æœ': analysis_result,
                    'è§‚ç‚¹æå–': points_result,
                    'æ£€æŸ¥ç»“æœ': inspection_result,
                    'å¥½å·®è¯„ç»“æœ': str(output_result)
                })
                
                # ç«‹å³ä¿å­˜å•æ¡ç»“æœ
                pd.DataFrame([result]).to_csv(output_csv, mode='a', header=False, index=False, encoding='utf-8-sig')
                
                progress_text += f"âœ“ ç¬¬ {idx+1} æ¡è¯„è®ºåˆ†æå®Œæˆå¹¶ä¿å­˜\n"
                
            except Exception as e:
                progress_text += f"âœ— ç¬¬ {idx+1} æ¡è¯„è®ºåˆ†æå¤±è´¥ï¼š{str(e)}\n"
                continue

        # è¯»å–åˆ†æç»“æœè¿›è¡Œæ•°æ®å¤„ç†
        data_analyzor = DataAnalyzor(criteria_path=f"./modules/criterias/{product_type}_criteria.csv")
        data_analyzor.analyze(file_path=output_csv, output_path=output_xlsx)

        # å¤„ç†å®Œæˆåç§»é™¤ç”¨æˆ·çŠ¶æ€
        if user_id in active_users:
            del active_users[user_id]

        return progress_text + "åˆ†æå®Œæˆï¼", output_xlsx

    except Exception as e:
        # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿè¦ç§»é™¤ç”¨æˆ·çŠ¶æ€
        if user_id in active_users:
            del active_users[user_id]
        return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}", None

def update_active_users_display():
    """æ›´æ–°æ´»è·ƒç”¨æˆ·æ˜¾ç¤º"""
    return get_active_users()

def create_visualization(excel_file):
    """åˆ›å»ºæ•°æ®å¯è§†åŒ–"""
    if excel_file is None:
        return "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶", None, None
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(excel_file):
            return "æ–‡ä»¶ä¸å­˜åœ¨", None, None
        
        # ç”ŸæˆHTMLæ–‡ä»¶è·¯å¾„
        base_name = os.path.splitext(os.path.basename(excel_file))[0]
        html_file = f"./visualizations/{base_name}_dashboard.html"
        
        # åˆ›å»ºå¯è§†åŒ–ï¼Œä¼ å…¥HTMLè¾“å‡ºè·¯å¾„ï¼Œä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
        fig = create_quick_visualization(excel_file, output_html_path=html_file, auto_open_browser=False)
        
        # è¿”å›æˆåŠŸä¿¡æ¯ã€æ–‡ä»¶è·¯å¾„å’Œå›¾è¡¨å¯¹è±¡
        return f"âœ… å¯è§†åŒ–åˆ›å»ºæˆåŠŸï¼\nğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {html_file}\nğŸ¯ å¯ä»¥åœ¨å³ä¾§æŸ¥çœ‹å›¾è¡¨ï¼Œä¹Ÿå¯ä»¥ä¸‹è½½HTMLæ–‡ä»¶", html_file, fig
        
    except Exception as e:
        return f"âŒ åˆ›å»ºå¯è§†åŒ–æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}", None, None

def upload_excel_for_visualization(file):
    """ä¸Šä¼ Excelæ–‡ä»¶ç”¨äºå¯è§†åŒ–"""
    if file is None:
        return "è¯·ä¸Šä¼ Excelæ–‡ä»¶", None
    
    if not file.name.endswith('.xlsx'):
        return "è¯·ä¸Šä¼ .xlsxæ ¼å¼çš„Excelæ–‡ä»¶", None
    
    return f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {os.path.basename(file.name)}", file

# æ„å»ºç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("# è¯„è®ºåˆ†æç³»ç»Ÿ")
    
    # æ´»è·ƒç”¨æˆ·æ˜¾ç¤ºç»„ä»¶æ”¾åœ¨æœ€å‰é¢
    with gr.Row():
        active_users_display = gr.Textbox(label="æ´»è·ƒç”¨æˆ·", lines=5, value="å½“å‰æ²¡æœ‰æ´»è·ƒç”¨æˆ·")
    with gr.Row():
        update_btn = gr.Button("åˆ·æ–°æ´»è·ƒç”¨æˆ·")
        update_btn.click(fn=update_active_users_display, outputs=active_users_display)
    
    # ä½¿ç”¨Tabç»„ä»¶åˆ†ç¦»åŠŸèƒ½
    with gr.Tabs():
        # è¯„è®ºåˆ†ææ ‡ç­¾é¡µ
        with gr.TabItem("è¯„è®ºåˆ†æ"):
            with gr.Row():
                with gr.Column():
                    file_input = gr.File(label="ä¸Šä¼ æ–‡ä»¶")
                    asin_input = gr.Textbox(label="ASIN")
                    model_type = gr.Dropdown(
                        choices=["Qwen", "OpenAI", "API2D"],
                        label="é€‰æ‹©æ¨¡å‹",
                        value="Qwen"
                    )
                    
                    # å®šä¹‰ä¸åŒæ¨¡å‹ç±»å‹çš„ç‰ˆæœ¬é€‰é¡¹
                    model_versions = {
                        "Qwen": ["qwen-plus", "qwen-plus-latest"],
                        "OpenAI": ["gpt-4.1-2025-04-14", "gpt-4.1-mini-2025-04-14"],
                        "API2D": ["gpt-4.1-2025-04-14", "gpt-4.1-mini-2025-04-14", "qwen-plus", "claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
                    }
                    
                    model_version = gr.Dropdown(
                        choices=model_versions["Qwen"],
                        label="é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬",
                        value=model_versions["Qwen"][0]
                    )
                    
                    def update_model_version(model_type):
                        return gr.update(
                            choices=model_versions[model_type],
                            value=model_versions[model_type][0],
                            interactive=True
                        )
                    
                    model_type.change(
                        fn=update_model_version,
                        inputs=[model_type],
                        outputs=[model_version]
                    )
                    
                    api_key = gr.Textbox(label="API Key", type="password")
                    product_type = gr.Dropdown(
                        choices=list(POINTS.keys()),
                        label="é€‰æ‹©äº§å“ç±»å‹",
                        value=list(POINTS.keys())[0]
                    )
                    template = gr.Dropdown(
                        choices=list(POINTS.keys()),
                        label="æç¤ºè¯æ¨¡æ¿",
                        value=list(POINTS.keys())[0]
                    )
                    # å¢åŠ ä¸€ä¸ªæç¤ºï¼Œå°±æ˜¯è¯´ä»¥ä¸‹æ¯ä¸€ä¸ªå‹¾é€‰äº†éƒ½ä¼šå¢åŠ æ¶ˆè€—å’Œç­‰å¾…æ—¶é—´
                    gr.Markdown("ä»¥ä¸‹æ¯ä¸€ä¸ªå‹¾é€‰äº†éƒ½ä¼šå¢åŠ æ¶ˆè€—å’Œç­‰å¾…æ—¶é—´ï¼Œè¯·è°¨æ…å‹¾é€‰")
                    need_translate = gr.Checkbox(label="éœ€è¦å¤§æ¨¡å‹ç¿»è¯‘", value=False)
                    need_inspect = gr.Checkbox(label="éœ€è¦å¤§æ¨¡å‹åå®¡æŸ¥", value=False)
                    need_points_extract = gr.Checkbox(label="éœ€è¦æ— ç›‘ç£ä½“éªŒç‚¹æå–", value=False)
                    analyze_btn = gr.Button("å¼€å§‹åˆ†æ")
                    progress = gr.Textbox(label="è¿›åº¦", lines=10)
                    output_file = gr.File(label="åˆ†æç»“æœ")
        
        # æ•°æ®å¯è§†åŒ–æ ‡ç­¾é¡µ
        with gr.TabItem("æ•°æ®å¯è§†åŒ–"):
            gr.Markdown("## ğŸ“Š æ•°æ®å¯è§†åŒ–")
            gr.Markdown("ä¸Šä¼ å·²åˆ†æçš„Excelæ–‡ä»¶æ¥ç”Ÿæˆäº¤äº’å¼å¯è§†åŒ–å›¾è¡¨")
            
            with gr.Row():
                with gr.Column():
                    # å¯è§†åŒ–æ–‡ä»¶ä¸Šä¼ 
                    viz_file_input = gr.File(
                        label="ä¸Šä¼ Excelæ–‡ä»¶", 
                        file_types=[".xlsx"],
                        type="filepath"
                    )
                    
                    # å¯è§†åŒ–æŒ‰é’®
                    viz_btn = gr.Button("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–", variant="primary")
                    
                    # å¯è§†åŒ–çŠ¶æ€æ˜¾ç¤º
                    viz_status = gr.Textbox(label="å¯è§†åŒ–çŠ¶æ€", lines=5)
                    
                    # HTMLæ–‡ä»¶ä¸‹è½½
                    viz_download = gr.File(label="ä¸‹è½½å¯è§†åŒ–HTMLæ–‡ä»¶")
                
                with gr.Column():
                    # å¯è§†åŒ–å›¾è¡¨æ˜¾ç¤ºåŒºåŸŸ
                    viz_plot = gr.Plot(label="å¯è§†åŒ–å›¾è¡¨")
    
    # ç»‘å®šåˆ†æåŠŸèƒ½
    analyze_btn.click(
        fn=analyze_reviews,
        inputs=[
            file_input, asin_input, model_type, api_key, product_type,
            template, need_translate, need_inspect, need_points_extract
        ],
        outputs=[progress, output_file]
    )
    
    # ç»‘å®šå¯è§†åŒ–åŠŸèƒ½
    viz_btn.click(
        fn=create_visualization,
        inputs=[viz_file_input],
        outputs=[viz_status, viz_download, viz_plot]
    )

if __name__ == "__main__":
    demo.launch(share=False, server_name="0.0.0.0", server_port=7860)
