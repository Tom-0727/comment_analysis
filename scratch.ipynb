{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3',  \n",
    "                       use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.\n",
    "                            )['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2)['dense_vecs']\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['标题', '内容', '星级', '赞同数', '评论链接', '评论时间', '好评点1', '好评点2', '好评点3', '好评点4',\n",
      "       '好评点5', '好评点6', '差评点1', '差评点2', '差评点3', '差评点4', '差评点5', '差评点6', '差评点7',\n",
      "       'version', 'v1', 'v1_4o_mini', 'v1_4o'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:58<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:  v1_4o\n",
      "total_extraction: 270\n",
      "correct_extraction: 128\n",
      "wrong_extraction: 142\n",
      "precision: 0.4740740740740741\n",
      "recall: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from modules.agent import CommentAnalysisAgent\n",
    "\n",
    "\n",
    "\n",
    "def read_csv(testset_path, version='default'):\n",
    "    # 读取测试集\n",
    "    df = pd.read_csv(testset_path, sep='\\t')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    df['v1_4o_mini'] = df['version']\n",
    "    df[version] = ''\n",
    "    print(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate(robot, testset, testset_path, version):\n",
    "\n",
    "    length = len(testset)\n",
    "    for i in tqdm(range(length)):\n",
    "        comment = testset.iloc[i]['内容']\n",
    "        if not isinstance(comment, str):\n",
    "            continue\n",
    "\n",
    "        response = robot.comment_analyze(comment)\n",
    "        testset.loc[i, version] = response\n",
    "    \n",
    "    testset.to_csv(testset_path, index=False, sep='\\t')\n",
    "\n",
    "    return testset\n",
    "\n",
    "\n",
    "def metric_calculate(testset, version):\n",
    "    total_extraction = 0\n",
    "    correct_extraction = 0\n",
    "    wrong_extraction = 0\n",
    "    expected_extraction = 0\n",
    "\n",
    "    length = len(testset)\n",
    "    for i in range(length):\n",
    "        comment = testset.iloc[i]['内容']\n",
    "        if not isinstance(comment, str):\n",
    "            continue\n",
    "\n",
    "        good_points = []\n",
    "        bad_points = []\n",
    "        # 很多column是好评点x, 差评点x的格式，从1开始，动态遍历所有这些columns，存储到good_points和bad_points中\n",
    "        for j in range(1, 100):\n",
    "            try:\n",
    "                good_point = testset.iloc[i]['好评点' + str(j)]\n",
    "            except:\n",
    "                break\n",
    "            if pd.notna(good_point):\n",
    "                good_points.append(good_point)\n",
    "        for j in range(1, 100):\n",
    "            try:\n",
    "                bad_point = testset.iloc[i]['差评点' + str(j)]\n",
    "            except:\n",
    "                break\n",
    "            if pd.notna(bad_point):\n",
    "                bad_points.append(bad_point)\n",
    "        \n",
    "        expected_extraction += len(good_points) + len(bad_points)\n",
    "        response = testset.iloc[i][version]\n",
    "        try:\n",
    "            output = eval(response)\n",
    "            # 遍历 output，将数据存入 DataFrame\n",
    "            \n",
    "            for key, value in output.items():\n",
    "                total_extraction += 1\n",
    "                if key[:3] == '好评点':\n",
    "                    if value in good_points:\n",
    "                        correct_extraction += 1\n",
    "                    else:\n",
    "                        wrong_extraction += 1\n",
    "                elif key[:3] == '差评点':\n",
    "                    if value in bad_points:\n",
    "                        correct_extraction += 1\n",
    "                    else:\n",
    "                        wrong_extraction += 1\n",
    "        except:\n",
    "            pass\n",
    "    print('total_extraction:', total_extraction)\n",
    "    print('correct_extraction:', correct_extraction)\n",
    "    print('wrong_extraction:', wrong_extraction)\n",
    "    precision = correct_extraction / total_extraction\n",
    "    recall = correct_extraction / expected_extraction\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "\n",
    "    return precision, recall\n",
    "        \n",
    "\n",
    "with open(\"openai_keys.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "my_key = data['tom']['key']\n",
    "robot = CommentAnalysisAgent(openai_key=my_key, model=\"gpt-4o-2024-08-06\")  # gpt-4o-2024-08-06  gpt-4o-mini-2024-07-18\n",
    "\n",
    "version = 'v1_4o'\n",
    "testset_path = './docs/Comment_Analysis_Testset.csv'\n",
    "testset = read_csv(testset_path, version)\n",
    "\n",
    "testset = evaluate(robot, testset, testset_path, version)\n",
    "\n",
    "print('version: ', version)\n",
    "precision, recall = metric_calculate(testset, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_extraction: 309\n",
      "correct_extraction: 148\n",
      "wrong_extraction: 161\n",
      "precision: 0.47896440129449835\n",
      "recall: 0.578125\n"
     ]
    }
   ],
   "source": [
    "print('version': version)\n",
    "precision, recall = metric_calculate(testset, version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
